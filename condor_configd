#!/usr/bin/python
#   Copyright 2008 Red Hat, Inc.
#
#   Licensed under the Apache License, Version 2.0 (the "License");
#   you may not use this file except in compliance with the License.
#   You may obtain a copy of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS,
#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#   See the License for the specific language governing permissions and
#   limitations under the License.

import os
import sys
import logging
import signal
import time
import socket
import threading
import getopt
import Queue
import random
import tempfile
import shutil
import stat
from qmf.console import Session, Console
from condorutils.log import *
from condorutils.readconfig import *
from wallabyclient import WallabyHelpers
from wallabyclient.exceptions import WallabyUnsupportedAPI
try:
   import pwd
except:
   pass


class Timer (threading.Thread):
   def __init__ (self, interval, function, args=[], kwargs={}):
      threading.Thread.__init__(self)
      self.interval = interval
      self.function = function
      self.args = args
      self.kwargs = kwargs
      self.setDaemon(True)
      self.finished = threading.Event()


   def stop (self):
      self.finished.set()
      self.join()


   def run (self):
      while not self.finished.isSet():
         self.finished.wait(self.interval)
         if not self.finished.isSet():
            self.function(*self.args, **self.kwargs)


class EventConsole(Console):
   def __init__(self):
      self.node = []
      self.logger_name = ''
      self.agent = []


   def config(self, node_name, log_name):
      self.node_name = node_name
      self.logger_name = log_name


   def newAgent(self, agent):
      global reconnect_qmf

      if agent.label == 'com.redhat.grid.config:Store':
         log(logging.DEBUG, self.logger_name, 'Established connection to the configuration store')
         self.agent = agent
         reconnect_qmf = True


   def delAgent(self, agent):
      global stop_running

      if agent.label == 'com.redhat.grid.config:Store':
         if stop_running == False:
            log(logging.DEBUG, self.logger_name, 'Lost connection to the configuration store')
         self.agent = []


   def event(self, broker, event):
      global version_queue

      if event.getClassKey().getClassName() == 'NodeUpdatedNotice':
         log(logging.DEBUG, self.logger_name, 'Received a NodeUpdatedNotice')
         args = event.getArguments()
         nodes = args['nodes']
         if self.node_name in nodes or '*' in nodes:
            log(logging.DEBUG, self.logger_name, 'The event is for this node')
            event_ver = int(args['version'])
            try:
               version_queue.put(event_ver, False)
            except Queue.Full, error:
               log(logging.INFO, self.logger_name, 'Configuration version queue full.  Discarding event for version "%d"' % event_ver)

   def get_store_agent(self):
      return self.agent


class Service:
   def __init__(self):
      self.broker = None
      self.console = None
      self.session = None
      self.interval = 0
      self.node_obj = []
      self.logger_name = ''
      self.filename = ''
      self.node_name = ''
      self.timer = None
      self.lock = threading.Lock()
      self.managedfile = ''
      self.config_dir = ''
      self.override_dir = ''
      self.store = None
      self.old_config = ''


   def init(self, node, name):
      self.console = EventConsole()
      self.session = Session(self.console, manageConnections=True, rcvObjects=True, rcvHeartbeats=False, rcvEvents=True, userBindings=True)
      self.session.bindEvent('com.redhat.grid.config', 'NodeUpdatedNotice')
      self.session.bindAgent('com.redhat.grid.config', 'Store')
      self.logger_name = name
      self.node_name = node


   def config(self, filename, user='', password=''):
      global stop_running 

      if self.broker != None:
         self.session.delBroker(self.broker)
         self.broker = None

      try:
         broker_ip = read_condor_config('QMF_BROKER', ['HOST'])['host']
         if broker_ip.strip() == '':
            broker_ip = '127.0.0.1'
      except ConfigError, error:
         # Broker host not defined, so exit
         log(logging.ERROR, self.logger_name, '%s.  Exiting' % error.msg)
         return(False)

      try:
         val = read_condor_config('QMF_BROKER', ['PORT'])
         broker_port = int(val['port'])
      except ConfigError, error:
         log(logging.DEBUG, self.logger_name, '%s. Using default (5672)' % error.msg)
         broker_port = 5672

      try:
         val = read_condor_config('QMF_BROKER', ['AUTH_MECHANISM'])
         broker_auth_methods = str(val['auth_mechanism']).replace(',', ' ')
      except ConfigError, error:
         log(logging.DEBUG, self.logger_name, '%s. Using defaults' % error.msg)
         broker_auth_methods = 'ANONYMOUS PLAIN GSSAPI'

      try:
         val = read_condor_config('QMF_CONFIGD', ['CHECK_INTERVAL'])
         self.interval = int(val['check_interval'])
      except ConfigError, error:
         log(logging.INFO, self.logger_name, '%s. Node configuration evaluation disabled' % error.msg)
         self.interval = 0

      if filename == '':
         try:
            self.managedfile = read_condor_config('LOCAL_CONFIG', ['FILE'])['file']
         except:
            log(logging.ERROR, self.logger_name, 'LOCAL_CONFIG_FILE not defined.  Unable to write configuration file')
            return(False)
      else:
         self.managedfile = filename
      log(logging.DEBUG, self.logger_name, 'Writing configuration file to "%s"' % self.managedfile)

      try:
         self.config_dir = read_condor_config('LOCAL_CONFIG', ['DIR'])['dir']
         if os.access(self.config_dir, os.F_OK) != True or os.access(self.config_dir, os.R_OK) != True:
            log(logging.ERROR, self.logger_name, '"%s" either is not a directory or has incorrect permissions.  Exiting' % self.config_dir)
            return(False)
      except:
         log(logging.ERROR, self.logger_name, 'LOCAL_CONFIG_DIR not defined.  Unable to read configuration files.  Exiting')
         return(False)

      try:
         self.override_dir = read_condor_config('QMF_CONFIGD', ['OVERRIDE_DIR'])['override_dir']
         if os.access(self.override_dir, os.F_OK) != True or os.access(self.override_dir, os.R_OK) != True:
            log(logging.WARNING, self.logger_name, '"%s" either is not a directory or has incorrect permissions.  Configuration overrides will not take affect' % self.override_dir)
            self.override_dir = ''
      except:
         self.override_dir = ''

      if self.broker != None:
         try:
            self.session.delBroker(self.broker)
         except:
            self.broker = None

      if user != '' and password != '':
         broker_str = '%s/%s@%s:%d' % (user, password, broker_ip, broker_port)
      elif user != '':
         broker_str = '%s@%s:%d' % (user, broker_ip, broker_port)
      else:
         broker_str = '%s:%d' % (broker_ip, broker_port)

      try:
         self.broker = self.session.addBroker('amqp://%s' % broker_str, mechanisms=broker_auth_methods)
      except:
         if stop_running == False:
            log(logging.CRITICAL, self.logger_name, 'Unable to connect to broker "%s"' % broker_str)
         return(False)

      log(logging.DEBUG, self.logger_name, 'Connected to broker "%s"' % broker_str)
      return(True)


   def config_qmf_entities(self):
      global stop_running

      supported_api_versions = {20100804:0, 20100915:0, 20101031:1}

      if self.node_obj != None:
         self.node_obj = None

      agent = self.console.get_store_agent()
      try:
         obj = agent.getObjects(_class='Store', _package='com.redhat.grid.config')
      except:
         obj = []

      if obj == []:
         if stop_running == False:
            log(logging.CRITICAL, self.logger_name, 'Failed to contact configuration store')
         return(False)

      self.store = obj[0]

      # Check API version number
      try:
         WallabyHelpers.verify_store_api(self.store, supported_api_versions)
      except WallabyUnsupportedAPI, error:
         if error.minor == 0:
            store_api_version = error.major
         else:
            store_api_version = '%s.%s' % (error.major, error.minor)
         log(logging.CRITICAL, self.logger_name, 'The store is using an API version that is not supported (%s)' % store_api_version)
         return(False)

      result = self.store.getNode(self.node_name)
      if result.status != 0:
         if stop_running == False:
            log(logging.CRITICAL, self.logger_name, '(%d, %s): Store does not know about this node' % (result.status, result.text))
         return(False)
      else:
         try:
            obj = agent.getObjects(_objectId=result.outArgs['obj'])
         except:
            obj = []

         if obj == []:
            if stop_running == False:
               log(logging.CRITICAL, self.logger_name, 'Unable to get node information object')
            return(False)
         else:
            self.node_obj = obj[0]
            log(logging.DEBUG, self.logger_name, 'Retrieved node object from store')
      self.console.config(self.node_obj.name, self.logger_name)
      return(True)


   def setup_timers(self):
      # Setup the timer for checking configuration version
      if self.timer == None:
         if self.interval > 0:
            self.timer = Timer(self.interval, self.check_config_ver)
            self.timer.start()


   def shutdown(self):
      if self.timer != None:
         self.timer.stop()
         del self.timer
         self.timer = None
      if self.broker != None:
         self.session.delBroker(self.broker)
         self.broker = None


   def get_interval(self):
      return self.interval


   def check_config_ver(self, ver=0, force=False):
      log(logging.DEBUG, self.logger_name, 'Checking version of configuration')
      self.lock.acquire(True)
      if self.node_obj == []:
         log(logging.ERROR, self.logger_name, 'No node object from the store')
         if reconnect_qmf == True:
            if self.config_qmf_entities() == False:
               self.lock.release()
               return(False)
            else:
               reconnect_qmf = False
         else:
            self.lock.release()
            return(False)

      # If the passed version is 0, look at the last_updated_version
      if ver == 0:
         if self.update_node_obj() == False:
            self.lock.release()
            return(False)
         ver = int(self.node_obj.last_updated_version)

      # Install the new configuration (if needed)
      ret_val = True
      if self.get_config(ver, force) == False:
         # There was a problem retrieving the configuration.  Logging is
         # handled by the get_config function
         ret_val = False

      self.lock.release()
      return(ret_val)


   def update_node_obj(self):
      global reconnect_qmf, stop_running

      try:
         self.node_obj.update()
      except Exception, e:
         # Agent/broker has gone away
         if reconnect_qmf == True:
            if self.config_qmf_entities() == False:
               if stop_running == False:
                  log(logging.ERROR, self.logger_name, 'Unable to access configuration store')
               return(False)
            else:
               reconnect_qmf = False
         else:
            if stop_running == False:
               log(logging.ERROR, self.logger_name, 'Failed to update the node object')
               log(logging.ERROR, self.logger_name, 'Update Exception: %s' % str(e))
               log(logging.ERROR, self.logger_name, 'Node Object: %s' % str(self.node_obj))
               log(logging.ERROR, self.logger_name, 'Node Timestamps: %s' % str(self.node_obj.getTimestamps()))
               log(logging.ERROR, self.logger_name, 'Node Agent: %s' % str(self.node_obj.getAgent()))
               log(logging.ERROR, self.logger_name, 'Node Object ID: %s' % str(self.node_obj.getObjectId()))
            return(False)


   def process_version_q(self):
      global version_queue

      # Pull all versions off the queue and only process the latest
      version = -1
      size = 0
      while version_queue.empty() == False:
         try:
            version = version_queue.get(False)
            size = version_queue.qsize()
         except Queue.Empty:
            break

      if version != -1:
         # There was a new version in the queue
         if self.check_config_ver(version) == False:
            if version_queue.empty() == True:
               # There hasn't been another version to look at, so put
               # this one back as there was an error installing it
               version_queue.put(version, False)
               size += 1
      return size


   def get_config(self, version=0, force=False):
      global replacing_file, stop_running, old_config_filename

      # Check in with the store
      log(logging.DEBUG, self.logger_name, 'Performing a checkin with the store')
      try:
         self.node_obj.checkin(_timeout=20)
      except Exception, error:
         if stop_running == False:
            log(logging.ERROR, self.logger_name, 'Failed to check in with the store')
            log(logging.ERROR, self.logger_name, error)
         return(False)
      log(logging.DEBUG, self.logger_name, 'Checked in with the store')

      if self.update_node_obj() == False:
         return(False)

      # Get the current WALLABY_CONFIG_VERSION.  If the system is running the
      # version as what was received, then there's no need to do anything
      (retval, running_version, err) = run_cmd('condor_config_val WALLABY_CONFIG_VERSION')
      try:
         running_version = int(running_version.strip())
      except:
         running_version = 0
 
      if version == running_version and force == False:
         log(logging.DEBUG, self.logger_name, 'The system is already running configuration version "%d"' % version)
         return(True)
      else:
         log(logging.INFO, self.logger_name, 'Retrieving configuration version "%d" from the store' % version)
   
         # Save the current configuraton
         (file_hdl,self.old_config) = tempfile.mkstemp('.tmp', old_config_filename, text=True)
         (retval, config_dump, err) = run_cmd('condor_config_val -dump')

         # Write the config from the dump
         for line in config_dump.split('\n'):
            if 'local_config_file' not in line.lower() and \
               'local_config_dir' not in line.lower():
               os.write(file_hdl, '%s\n' % line)
         os.close(file_hdl)

         # Retrieve the node's configuration
         try:
            if version <= 0:
               result = self.node_obj.getConfig({})
            else:
               result = self.node_obj.getConfig({'version':version})
         except Exception, error:
            # Something has gone away
            if stop_running == False:
               log(logging.ERROR, self.logger_name, 'Exception when attempting to retrieve configuration version "%d" from the store' % version)
               log(logging.ERROR, self.logger_name, error)
            return(False)

         if result.status != 0:
            # Problem getting the configuration, so do nothing
            if stop_running == False:
               log(logging.ERROR, self.logger_name, 'Failed to retrieve configuration "%d" from the store (%d, %s)' % (version, result.status, result.text))
            return(False)
         else:
            config = result.outArgs['config']

         try:
            (file_hdl,file_name) = tempfile.mkstemp('.tmp', 'condor_config.local', text=True)
            # Write the config from the store into the file
            for key in config.keys():
               if key.strip().lower() == 'dc_daemon_list':
                  os.write(file_hdl, '%s =+ %s\n' % (key, config[key]))
               else:
                  os.write(file_hdl, '%s = %s\n' % (key, config[key]))

            # Add the wallaby group/feature information
            features = WallabyHelpers.get_node_features(self.node_obj, self.session, self.store)
            print_str = ''
            for feat in features:
               print_str += '%s,' % feat
            print_str = print_str[:-1]
            os.write(file_hdl, 'WallabyFeatures = "%s"\n' % print_str)

            print_str = ''
            for group in self.node_obj.memberships:
               print_str += '%s,' % group
            print_str = print_str[:-1]
            os.write(file_hdl, 'WallabyGroups = "%s"\n' % print_str)
            os.write(file_hdl, 'MASTER_ATTRS = $(MASTER_ATTRS), WallabyFeatures, WallabyGroups\n')
            os.write(file_hdl, 'STARTD_ATTRS = $(STARTD_ATTRS), WallabyFeatures, WallabyGroups\n')

            # Now append the configuration from the configd configuration
            # file
            cfg_name = os.path.normpath('%s/99configd.config' % self.config_dir)
            cfg_file = open(cfg_name, 'r')
            for line in cfg_file:
               os.write(file_hdl, line)
            cfg_file.close()

            # Process any overriden parameters
            if self.override_dir != '':
               entries = os.listdir(self.override_dir)
               for file in sorted(entries):
                  fname = os.path.normpath('%s/%s' % (self.override_dir, file))
                  if os.access(fname, os.R_OK) == True:
                     try:
                        hdl = open(fname, 'r')
                        os.write(file_hdl, '# Override from "%s"\n' % fname)
                        for line in hdl:
                           os.write(file_hdl, line)
                     except:
                        log(logging.ERROR, self.logger_name, 'Problem reading file "%s"' % fname)
                     hdl.close()
                  else:
                     log(logging.ERROR, self.logger_name, 'Unable to access "%s".  Ignoring override file' % fname)

            # Ensure permissions for restart/reconfig
            try:
               subs = self.console.get_store_agent().getObjects(_class='Subsystem', _package='com.redhat.grid.config')

               dlist = []
               for d in config['DAEMON_LIST'].split(','):
                  d = d.strip()
                  if d != '':
                     dlist += [d.upper()]

               for sub in subs:
                  name = sub.name.upper()
                  if name in dlist:
                     os.write(file_hdl, '%s.SEC_ADMINISTRATOR_AUTHENTICATION_METHODS = $(%s.SEC_ADMINISTRATOR_AUTHENTICATION_METHODS), FS, NTLM, CLAIMTOBE\n' % (name, name))
            except Exception, error:
               log(logging.ERROR, self.logger_name, 'Store: %s' % error)
               log(logging.WARNING, self.logger_name, 'Failed to retrieve subsystem list.  Configuration could break restart/reconfig functionality')

            os.close(file_hdl)
         except IOError:
            try:
               os.close(file_hdl)
               os.remove(file_name)
            except:
               pass
            log(logging.ERROR, self.logger_name, 'Failed to read configd configuration/override file(s).  Not writing configuration file')
            return(False)
         except:
            try:
               os.close(file_hdl)
               os.remove(file_name)
            except:
               pass
            log(logging.ERROR, self.logger_name, 'Failed to write configuration to temp file')
            return(False)
   
         # Verify the config file is valid
         (retval, out, err) = run_cmd('condor_config_val -dump', environ={'CONDOR_CONFIG':'%s' % file_name})
         if retval != 0:
            log(logging.ERROR, self.logger_name, 'Configuration is invalid.  Discarding')
            os.remove(file_name)
            return(False)
   
         # Install the file for condor to use
         replacing_file = True
         if os.path.exists(self.managedfile):
            os.remove(self.managedfile)
         try:
            shutil.move(file_name, self.managedfile)
         except:
            log(logging.ERROR, self.logger_name, 'Error installing new configuration file')
            os.remove(file_name)
            replacing_file = False
            return(False)
         os.chmod(self.managedfile, stat.S_IRUSR|stat.S_IWUSR|stat.S_IRGRP|stat.S_IWGRP|stat.S_IROTH)
         replacing_file = False
         log(logging.INFO, self.logger_name, 'Retrieved configuration from the store')
   
         # Have the store tell us which subsystems to restart/reconfig
         try:
            result = self.node_obj.whatChanged(running_version, version)
         except:
            if stop_running == False:
               log(logging.ERROR, self.logger_name, 'Unable to retrieve configuration differences')
            return(False)

         if result.status != 0:
            if stop_running == False:
               log(logging.ERROR, self.logger_name, 'Store error: %d, %s' % (result.status, result.text))
               log(logging.ERROR, self.logger_name, 'Failed to retrive differences between versions "%d" and "%d".  No update performed' % (running_version, version))
            return(False)
         else:
            restart_list = result.outArgs['restart']
            reconfig_list = result.outArgs['affected']

         log(logging.DEBUG, self.logger_name, 'Daemons to restart: %s' % restart_list)
         log(logging.DEBUG, self.logger_name, 'Daemons to reconfig: %s' % reconfig_list)

         # Determine the list of daemons the master is running, and only send
         # events to these daemons.  Any new daemons that should be running (or
         # any daemons that should be stopped) will be handled by commands sent
         # to the master
         (retval, daemons, err) = run_cmd('condor_config_val -master DAEMON_LIST')
         daemon_list = []
         if daemons != None:
            for daemon in daemons.split(','):
               daemon = daemon.strip()
               if daemon != '':
                  daemon_list += [daemon.lower()]
   
         # Process the subsystem lists and act upon them.  Start by processing
         # the daemons to restart, and if master is listed then don't process
         # anything else because restarting the master will take care of
         # everything
         cmd = 'condor_restart'
         if 'master' in restart_list:
            return(self.send_condor_command(cmd, 'master'))
         else:
            success = self.act_upon_subsys_list(cmd, restart_list, daemon_list)
   
            # If the reconfig list isn't empty, then send a reconfig to
            # the master daemon
            if reconfig_list != []:
               return(self.send_condor_command('condor_reconfig', 'master') and success)
   
   
   def act_upon_subsys_list(self, command, list, running_daemons):
      nondc_daemons = ['ll_daemon', 'qmf_configd']
      all_success = True

      for subsys in list:
         subsys = str(subsys.strip())
         if subsys.lower() not in running_daemons:
            log(logging.DEBUG, self.logger_name, 'Not sending "%s" to subsystem "%s" since it is not currently running' % (command, subsys))
         else:
            if subsys.lower() in nondc_daemons:
               # Non-daemoncore daemon, so send an off first then an on
               # command.  It's possible the daemon isn't running for some
               # reason, and that is ok.  The important thing is to ensure
               # it is started
               self.send_condor_command('condor_off', subsys)
               if self.send_condor_command('condor_on', subsys) == False:
                  all_success = False
            else:
               if self.send_condor_command(command, subsys) == False:
                  all_success = False
      return(all_success)


   def send_condor_command(self, command, subsystem):
      log(logging.DEBUG, self.logger_name, 'Sending command "%s" to subsystem "%s"' % (command, subsystem))
      (retval, out, err) = run_cmd('%s -subsystem %s' % (command, subsystem), environ={'CONDOR_CONFIG':'%s' % self.old_config})
      if retval != 0:
         log(logging.ERROR, self.logger_name, 'Failed to send command "%s" to subsystem "%s" (retval: %d, stdout: "%s", stderr: "%s")' % (command, subsystem, retval, out, err))
         return(False)
      else:
         log(logging.DEBUG, self.logger_name, 'Sent command "%s" to subsystem "%s"' % (command, subsystem))
         return(True)


def exit_signal_handler(signum, frame):
   global service, stop_running, logger_name

   log(logging.DEBUG, logger_name, 'Shutting down')
   log(logging.DEBUG, logger_name, 'Closing QMF connections')
   if service != None:
      service.shutdown()
      del service
      service = None
   log(logging.DEBUG, logger_name, 'Closed QMF connections')
   log(logging.DEBUG, logger_name, 'Setting stop flag')
   stop_running = True

def test_for_shutdown():
   global pidfile, logger_name

   log(logging.DEBUG, logger_name, 'Testing for shutdown file')
   if os.path.isfile(pidfile):
      log(logging.DEBUG, logger_name, 'Found shutdown file')
      os.remove(pidfile)
      exit_signal_handler(signal.SIGTERM, None)

version_queue = Queue.Queue()
service = Service()
stop_running = False
replacing_file = False
reconnect_qmf = False
pidfile = os.path.normpath(os.getcwd() + '/.pid' + str(os.getpid()))
logger_name = os.path.basename(sys.argv[0])
old_config_filename = 'condor.old_config'

def main(argv=None):
   global service, stop_running, replacing_file, reconnect_qmf, version_queue, logger_name, old_config_filename

   if argv is None:
      argv = sys.argv

   try:
      file = {}
      retrieve = False
      node_name = socket.gethostname()
      config_file = ''
      username = ''
      passwd = ''
      log_level = logging.INFO
      num_attempts = 0
      last_attempt = 0

      long_opts = ['debug', 'hostname=', 'logfile=', 'managedfile=', 
                   'password=', 'retrieve', 'user=']
      try:
         opts, args = getopt.gnu_getopt(argv[1:], 'dh:l:m:rP:U:', long_opts)
      except getopt.GetoptError, error:
         print str(error)
         return(1)

      for option, arg in opts:
         if option in ('-d', '--debug'):
            log_level = logging.DEBUG
         if option in ('-h', '--hostname'):
            node_name = arg
         if option in ('-l', '--logfile'):
            file['log'] = arg
         if option in ('-m', '--managedfile'):
            config_file = arg
         if option in ('-P', '--password'):
            passwd = arg
         if option in ('-r', '--retrieve'):
            retrieve = True
         if option in ('-U', '--user'):
            username = arg


      # Configure the logging system
      if 'log' not in file.keys():
         try:
            file = read_condor_config('QMF_CONFIGD', ['LOG'])
         except ConfigError, error:
            print 'Error: %s.  Exiting' % error.msg
            return(1)

      try:
         size = int(read_condor_config('MAX_QMF_CONFIGD', ['LOG'])['log'])
      except:
         size = 1000000

      try:
         backoff_factor = int(read_condor_config('QMF_CONFIGD', ['BACKOFF_FACTOR']))
         if backoff_factor < 0:
            backoff_factor = 2
      except:
         backoff_factor = 2

      try:
         backoff_const = int(read_condor_config('QMF_CONFIGD', ['BACKOFF_CONSTANT']))
         if backoff_const < 0:
            backoff_const = 9
      except:
         backoff_const = 9

      # Set signal handlers
      signal.signal(signal.SIGINT, exit_signal_handler)
      signal.signal(signal.SIGTERM, exit_signal_handler)
      signal.signal(signal.SIGABRT, exit_signal_handler)
      signal.signal(signal.SIGILL, exit_signal_handler)
      signal.signal(signal.SIGFPE, exit_signal_handler)
      signal.signal(signal.SIGSEGV, exit_signal_handler)
      if os.name != 'nt' and os.name != 'ce':
         # These aren't available on windows
         signal.signal(signal.SIGQUIT, exit_signal_handler)

         # Run as the user condor if running as root
         if os.geteuid() == 0:
            # Get the uid and gid for the condor user
            pw_data = pwd.getpwnam('condor')
            os.setregid(pw_data[3], pw_data[3])
            os.setreuid(pw_data[2], pw_data[2])

      # Create the log file
      try:
         base_logger = create_file_logger(logger_name, file['log'], log_level, size=size)
      except:
         print 'Failed to open log file.  Exiting'
         return(1)

      log(logging.INFO, logger_name, 'Starting Up')
      log(logging.INFO, logger_name, 'Hostname is "%s"' % node_name)

      # Remove all temp configuration files
      log(logging.INFO, logger_name, 'Cleaning up temporary configuration files')
      temp_dir = tempfile.gettempdir()
      for file in os.listdir(temp_dir):
         full_path = os.path.normpath('%s/%s' % (temp_dir, file))
         if old_config_filename in file:
            log(logging.DEBUG, logger_name, 'Deleting temporary configuration file %s' % full_path)
            os.remove(full_path)

      # Retrieve the broker information from condor's configuration file
      if service != None:
         service.init(node_name, logger_name)
      if service != None and service.config(config_file, username, passwd) != True:
         if retrieve == True:
            print 'Error: Unable to retrieve configuration'
            log(logging.CRITICAL, logger_name, 'Unable to retrieve configuration')
         exit_signal_handler(0, 0)
         return(1)

      # Wait for connection to the store
      log(logging.DEBUG, logger_name, 'Looking for the store agent')
      while reconnect_qmf == False and stop_running == False:
         time.sleep(1)

      if reconnect_qmf == True:
         log(logging.DEBUG, logger_name, 'Found the store agent')

      if service != None:
         service.lock.acquire(True)
         if service.config_qmf_entities() == True:
            reconnect_qmf = False
         else:
            log(logging.WARNING, logger_name, 'Unable to access the store')
         service.lock.release()

         if retrieve == True:
            if reconnect_qmf == False and \
               service.check_config_ver(force=True) == False:
               print 'Error: Unable to retrieve configuration'
               log(logging.CRITICAL, logger_name, 'Unable to retrieve configuration')
            exit_signal_handler(0, 0)
            return(0)

         # Delay initial checkin after startup 
         random.seed()
         time.sleep(random.randint(0, 10))
         service.check_config_ver()
         service.setup_timers()

      if os.name == 'nt' or os.name == 'ce':
         # Need to set a Timer for shutdown on windows
         log(logging.INFO, logger_name, 'Setting windows shutdown Timer')
         shutdown_interval = int(read_condor_config('QMF_CONFIGD', ['WIN_INTERVAL'])['win_interval'])
         shutdown_timer = Timer(shutdown_interval,test_for_shutdown)
         shutdown_timer.start()

      # Loop forever until told to shutdown
      while stop_running == False or replacing_file == True:
         try:
            time.sleep(1)
            if reconnect_qmf == True:
               service.lock.acquire(True)
               if service.config_qmf_entities() == True:
                  reconnect_qmf = False
               service.lock.release()

            # Check to see if there is a new configuration version to install
            if version_queue.qsize() > 0:
               # There is a new configuration version, so trying to install it.
               # Record the time the last installation attempt was tried for
               # exponential backoff.
               if last_attempt == 0:
                  last_attempt = time.time()
               check_interval = service.get_interval()
               if num_attempts == 0 or \
                  (time.time() - last_attempt) >= next_attempt_interval or \
                  (next_attempt_time > check_interval and check_interval > 0):

                  if service.process_version_q() > 0:
                     # There's still a version in the queue, so there was a
                     # problem installing the configuruation.  This could be
                     # an OS hiccup, a store communcation issue, or that the
                     # configuration is just not valid.

                     # Subract a second to account to the sleep in the
                     # main loop
                     next_attempt_interval = (backoff_const + pow(backoff_factor, num_attempts))-1
                     num_attempts += 1
                  else:
                     # Installation was successful
                     num_attempts = 0
                  last_attempt = 0
         except:
            pass

      log(logging.INFO, logger_name, 'Exiting')
      logging.shutdown()
   except:
      if service != None:
         service.shutdown()
         del service
      return(1)

   return(0)

if __name__ == '__main__':
    sys.exit(main())
